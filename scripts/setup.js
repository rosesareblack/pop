#!/usr/bin/env node

const fs = require('fs-extra')
const path = require('path')
const { execSync } = require('child_process')
const inquirer = require('inquirer')
const chalk = require('chalk')

const log = (message, color = 'white') => {
  console.log(chalk[color](message))
}

async function main() {
  log('\nüöÄ AI Provider Configurator Setup\n', 'cyan')
  
  try {
    // Check if dependencies are installed
    if (!fs.existsSync(path.join(process.cwd(), 'node_modules'))) {
      log('üì¶ Installing dependencies...', 'yellow')
      execSync('npm install', { stdio: 'inherit' })
      log('‚úÖ Dependencies installed successfully!\n', 'green')
    }

    // Create .env.local if it doesn't exist
    const envPath = path.join(process.cwd(), '.env.local')
    if (!fs.existsSync(envPath)) {
      log('üìù Creating environment file...', 'yellow')
      fs.writeFileSync(envPath, `# AI Provider Configuration
# Generated by AI Provider Configurator Setup

# Choose your active provider: openai, anthropic, mistral, ollama
ACTIVE_AI_PROVIDER=

# OpenAI Configuration
OPENAI_API_KEY=
OPENAI_ENDPOINT=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# Anthropic Configuration  
ANTHROPIC_API_KEY=
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Mistral Configuration
MISTRAL_API_KEY=
MISTRAL_ENDPOINT=https://api.mistral.ai/v1
MISTRAL_MODEL=mistral-large-latest

# Ollama Configuration (Local)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama2
`)
      log('‚úÖ Environment file created!\n', 'green')
    }

    // Prompt for initial configuration
    const { configureNow } = await inquirer.prompt([
      {
        type: 'confirm',
        name: 'configureNow',
        message: 'Would you like to configure an AI provider now?',
        default: true
      }
    ])

    if (configureNow) {
      const { provider } = await inquirer.prompt([
        {
          type: 'list',
          name: 'provider',
          message: 'Which AI provider would you like to configure?',
          choices: [
            { name: 'üß† OpenAI (GPT models)', value: 'openai' },
            { name: 'üí¨ Anthropic (Claude models)', value: 'anthropic' },
            { name: '‚ö° Mistral AI', value: 'mistral' },
            { name: 'üñ•Ô∏è Ollama (Local models)', value: 'ollama' }
          ]
        }
      ])

      await configureProvider(provider, envPath)
    }

    log('\nüéâ Setup completed successfully!', 'green')
    log('\nNext steps:', 'cyan')
    log('1. Run "npm run dev" to start the development server', 'white')
    log('2. Open http://localhost:3000 in your browser', 'white')
    log('3. Use "npm run configure" for the interactive configuration wizard', 'white')
    log('\nHappy coding! üöÄ\n', 'green')

  } catch (error) {
    log(`\n‚ùå Setup failed: ${error.message}`, 'red')
    process.exit(1)
  }
}

async function configureProvider(provider, envPath) {
  let envContent = fs.readFileSync(envPath, 'utf8')
  const providerUpper = provider.toUpperCase()

  if (provider === 'ollama') {
    const { endpoint, model } = await inquirer.prompt([
      {
        type: 'input',
        name: 'endpoint',
        message: 'Ollama endpoint:',
        default: 'http://localhost:11434'
      },
      {
        type: 'input',
        name: 'model',
        message: 'Default model:',
        default: 'llama2'
      }
    ])

    envContent = updateEnvVar(envContent, `${providerUpper}_ENDPOINT`, endpoint)
    envContent = updateEnvVar(envContent, `${providerUpper}_MODEL`, model)
  } else {
    const { apiKey, model } = await inquirer.prompt([
      {
        type: 'password',
        name: 'apiKey',
        message: `${provider} API key:`,
        mask: '*'
      },
      {
        type: 'input',
        name: 'model',
        message: 'Default model:',
        default: getDefaultModel(provider)
      }
    ])

    envContent = updateEnvVar(envContent, `${providerUpper}_API_KEY`, apiKey)
    envContent = updateEnvVar(envContent, `${providerUpper}_MODEL`, model)
  }

  envContent = updateEnvVar(envContent, 'ACTIVE_AI_PROVIDER', provider)
  fs.writeFileSync(envPath, envContent)
  
  log(`‚úÖ ${provider} configured successfully!`, 'green')
}

function updateEnvVar(content, key, value) {
  const regex = new RegExp(`^${key}=.*$`, 'm')
  if (regex.test(content)) {
    return content.replace(regex, `${key}=${value}`)
  } else {
    return content + `\n${key}=${value}`
  }
}

function getDefaultModel(provider) {
  const defaults = {
    openai: 'gpt-4',
    anthropic: 'claude-3-sonnet-20240229',
    mistral: 'mistral-large-latest'
  }
  return defaults[provider] || ''
}

if (require.main === module) {
  main()
}